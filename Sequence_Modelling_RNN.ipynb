{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S9rE0cECyd7D"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset from Keras, keeping only the top 10,000 most frequent words\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences to ensure uniform length for all reviews\n",
        "max_len_short = 200  # Max length for short sequences (IMDB reviews)\n",
        "X_train_padded = pad_sequences(X_train, maxlen=max_len_short)\n",
        "X_test_padded = pad_sequences(X_test, maxlen=max_len_short)\n",
        "\n",
        "print(f\"X_train_padded shape: {X_train_padded.shape}, X_test_padded shape: {X_test_padded.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxK3E4flyj5W",
        "outputId": "e750988b-c0d7-4328-d69e-08f0e133cd5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_train_padded shape: (25000, 200), X_test_padded shape: (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate long sequences (e.g., Wikipedia-like data with 1500 tokens per sequence)\n",
        "long_sequences = np.random.randint(10000, size=(1000, 1500))  # 1000 samples, each with 1500 tokens\n",
        "labels_long = np.random.randint(2, size=(1000,))  # Binary labels for the simulated long sequences\n",
        "\n",
        "# Split long sequence dataset into training and testing sets\n",
        "X_train_long, X_test_long, y_train_long, y_test_long = train_test_split(long_sequences, labels_long, test_size=0.2)\n",
        "\n",
        "# Pad long sequences to a fixed length of 500 tokens\n",
        "max_len_long = 500  # Truncate/pad sequences to 500 tokens\n",
        "X_train_long_padded = pad_sequences(X_train_long, maxlen=max_len_long)\n",
        "X_test_long_padded = pad_sequences(X_test_long, maxlen=max_len_long)\n",
        "\n",
        "print(f\"X_train_long_padded shape: {X_train_long_padded.shape}, X_test_long_padded shape: {X_test_long_padded.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpJkgCe8ym9P",
        "outputId": "35059992-252a-480b-e88f-d11423b81e71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_long_padded shape: (800, 500), X_test_long_padded shape: (200, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build a Sequential RNN model\n",
        "def build_model_rnn(input_length, units=64, num_layers=1):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=input_length))\n",
        "    for i in range(num_layers):\n",
        "        if i == num_layers - 1:\n",
        "            model.add(SimpleRNN(units, return_sequences=False))\n",
        "        else:\n",
        "            model.add(SimpleRNN(units, return_sequences=True))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to build a Sequential LSTM model\n",
        "def build_model_lstm(input_length, units=64, num_layers=1):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=input_length))\n",
        "    for i in range(num_layers):\n",
        "        if i == num_layers - 1:\n",
        "            model.add(LSTM(units, return_sequences=False))\n",
        "        else:\n",
        "            model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xKP5sbwqyn6A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, units=64, num_layers=1, max_len=200, model_type='RNN'):\n",
        "    if model_type == 'RNN':\n",
        "        model = build_model_rnn(input_length=max_len, units=units, num_layers=num_layers)\n",
        "    else:\n",
        "        model = build_model_lstm(input_length=max_len, units=units, num_layers=num_layers)\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.round(y_pred).flatten()  # Convert predictions to binary labels\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_type} - Units: {units}, Layers: {num_layers}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "0R7dKtCEysip"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNNs on the IMDB dataset (short sequences)\n",
        "print(\"Short Sequence Dataset (IMDB)\")\n",
        "short_seq_results = []\n",
        "\n",
        "# RNN with 1 layer, 64 units\n",
        "short_seq_results.append(train_and_evaluate(X_train_padded, X_test_padded, y_train, y_test, units=64, num_layers=1, max_len=max_len_short))\n",
        "\n",
        "# RNN with 2 layers, 64 units\n",
        "short_seq_results.append(train_and_evaluate(X_train_padded, X_test_padded, y_train, y_test, units=64, num_layers=2, max_len=max_len_short))\n",
        "\n",
        "# RNN with 1 layer, 128 units\n",
        "short_seq_results.append(train_and_evaluate(X_train_padded, X_test_padded, y_train, y_test, units=128, num_layers=1, max_len=max_len_short))\n",
        "\n",
        "# RNN with 2 layers, 128 units\n",
        "short_seq_results.append(train_and_evaluate(X_train_padded, X_test_padded, y_train, y_test, units=128, num_layers=2, max_len=max_len_short))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFyKwY1wyvYk",
        "outputId": "e5c1c5dc-a58a-4b75-9ca7-e0172d67dec0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Short Sequence Dataset (IMDB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 112ms/step - accuracy: 0.6036 - loss: 0.6371 - val_accuracy: 0.8122 - val_loss: 0.4159\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 101ms/step - accuracy: 0.8347 - loss: 0.3872 - val_accuracy: 0.8014 - val_loss: 0.4563\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - accuracy: 0.9030 - loss: 0.2506 - val_accuracy: 0.8300 - val_loss: 0.4583\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 102ms/step - accuracy: 0.9819 - loss: 0.0677 - val_accuracy: 0.8160 - val_loss: 0.5675\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 108ms/step - accuracy: 0.9844 - loss: 0.0488 - val_accuracy: 0.7870 - val_loss: 0.6860\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step\n",
            "RNN - Units: 64, Layers: 1, Accuracy: 0.7844\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 167ms/step - accuracy: 0.5698 - loss: 0.6641 - val_accuracy: 0.7328 - val_loss: 0.5362\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 168ms/step - accuracy: 0.8563 - loss: 0.3421 - val_accuracy: 0.8284 - val_loss: 0.4291\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 164ms/step - accuracy: 0.9622 - loss: 0.1126 - val_accuracy: 0.8216 - val_loss: 0.5167\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.9817 - loss: 0.0594 - val_accuracy: 0.7528 - val_loss: 0.8078\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 168ms/step - accuracy: 0.9914 - loss: 0.0258 - val_accuracy: 0.7878 - val_loss: 0.8713\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step\n",
            "RNN - Units: 64, Layers: 2, Accuracy: 0.7758\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 144ms/step - accuracy: 0.5707 - loss: 0.6634 - val_accuracy: 0.6918 - val_loss: 0.5765\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 144ms/step - accuracy: 0.7855 - loss: 0.4840 - val_accuracy: 0.7886 - val_loss: 0.4603\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 143ms/step - accuracy: 0.6699 - loss: 0.6580 - val_accuracy: 0.7144 - val_loss: 0.5546\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 142ms/step - accuracy: 0.7789 - loss: 0.4693 - val_accuracy: 0.7240 - val_loss: 0.5630\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - accuracy: 0.7858 - loss: 0.4545 - val_accuracy: 0.5894 - val_loss: 0.6526\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step\n",
            "RNN - Units: 128, Layers: 1, Accuracy: 0.5965\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 290ms/step - accuracy: 0.5279 - loss: 0.6934 - val_accuracy: 0.5472 - val_loss: 0.7466\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 284ms/step - accuracy: 0.7026 - loss: 0.5645 - val_accuracy: 0.7586 - val_loss: 0.5277\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 281ms/step - accuracy: 0.7767 - loss: 0.4584 - val_accuracy: 0.6616 - val_loss: 0.6286\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 291ms/step - accuracy: 0.8193 - loss: 0.4006 - val_accuracy: 0.7270 - val_loss: 0.6295\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 272ms/step - accuracy: 0.8801 - loss: 0.2953 - val_accuracy: 0.7442 - val_loss: 0.6170\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step\n",
            "RNN - Units: 128, Layers: 2, Accuracy: 0.7482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNNs on the simulated long sequences (e.g., Wikipedia-like)\n",
        "print(\"\\nLong Sequence Dataset (Simulated Wikipedia)\")\n",
        "long_seq_results = []\n",
        "\n",
        "# RNN with 1 layer, 64 units\n",
        "long_seq_results.append(train_and_evaluate(X_train_long_padded, X_test_long_padded, y_train_long, y_test_long, units=64, num_layers=1, max_len=max_len_long))\n",
        "\n",
        "# RNN with 2 layers, 64 units\n",
        "long_seq_results.append(train_and_evaluate(X_train_long_padded, X_test_long_padded, y_train_long, y_test_long, units=64, num_layers=2, max_len=max_len_long))\n",
        "\n",
        "# RNN with 1 layer, 128 units\n",
        "long_seq_results.append(train_and_evaluate(X_train_long_padded, X_test_long_padded, y_train_long, y_test_long, units=128, num_layers=1, max_len=max_len_long))\n",
        "\n",
        "# RNN with 2 layers, 128 units\n",
        "long_seq_results.append(train_and_evaluate(X_train_long_padded, X_test_long_padded, y_train_long, y_test_long, units=128, num_layers=2, max_len=max_len_long))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkfa0ex2y101",
        "outputId": "ce6a62f0-7f52-4631-b49a-a7d21fb5828e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Long Sequence Dataset (Simulated Wikipedia)\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.5397 - loss: 0.6982 - val_accuracy: 0.5375 - val_loss: 0.7280\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.8242 - loss: 0.5400 - val_accuracy: 0.4500 - val_loss: 0.7031\n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.2986 - val_accuracy: 0.4688 - val_loss: 0.7118\n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.1318 - val_accuracy: 0.4812 - val_loss: 0.7300\n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.4750 - val_loss: 0.7576\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n",
            "RNN - Units: 64, Layers: 1, Accuracy: 0.5450\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.5018 - loss: 0.7180 - val_accuracy: 0.4812 - val_loss: 0.7118\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 542ms/step - accuracy: 0.9254 - loss: 0.3994 - val_accuracy: 0.5063 - val_loss: 0.7984\n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 0.4938 - val_loss: 0.9215\n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.5000 - val_loss: 1.0443\n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5000 - val_loss: 1.0818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 790 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x780d6bc924d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step\n",
            "RNN - Units: 64, Layers: 2, Accuracy: 0.5200\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 336ms/step - accuracy: 0.5035 - loss: 0.7316 - val_accuracy: 0.4812 - val_loss: 0.7341\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 468ms/step - accuracy: 0.6080 - loss: 0.6420 - val_accuracy: 0.4500 - val_loss: 0.7126\n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.7704 - loss: 0.5747 - val_accuracy: 0.5312 - val_loss: 0.6863\n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 372ms/step - accuracy: 0.9920 - loss: 0.4443 - val_accuracy: 0.5125 - val_loss: 0.7017\n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 621ms/step - accuracy: 0.9950 - loss: 0.2436 - val_accuracy: 0.3875 - val_loss: 0.8404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x780d6bb679a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n",
            "RNN - Units: 128, Layers: 1, Accuracy: 0.5600\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 824ms/step - accuracy: 0.5098 - loss: 0.7370 - val_accuracy: 0.5500 - val_loss: 0.6933\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 570ms/step - accuracy: 0.7950 - loss: 0.4743 - val_accuracy: 0.4938 - val_loss: 0.8232\n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 561ms/step - accuracy: 1.0000 - loss: 0.0399 - val_accuracy: 0.5375 - val_loss: 1.1712\n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 610ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5750 - val_loss: 1.3484\n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 649ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5188 - val_loss: 1.4779\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\n",
            "RNN - Units: 128, Layers: 2, Accuracy: 0.5950\n"
          ]
        }
      ]
    }
  ]
}